# EEEC dataset - Enriched Equity Evaluation Corpus

*Description:* EEC (Equity Evaluation Corpus) (Kiritchenko and Mohammad 2018) is a benchmark data set, designed for examining inappropriate biases in system predictions, and it consists of 8,640 English sentences chosen to tease out Racial and Gender related bias. Each sentence is labeled for the mood state it conveys, a task also known as Profile of Mood States (POMS). Each of the sentences in the data set is composed using one of eleven templates, with placeholders for a person’s name and the emotion it conveys. Designed as a bias detection benchmark, the sentences in EEC are very concise, which can make them not useful as training examples. If a classifier sees in training only a small number of examples, which differ only by the name of the person and the emotion word, it could easily memorize a mapping between emotion words and labels, and will not learn anything else. To solve this and create a more representative and natural data set for training, we expand the EEC data set, creating an enriched data set which we denote as Enriched Equity Evaluation Corpus, or EEEC. In this data set, we use the 11 templates of EEC and randomly add a prefix or suffix phrase, which can describe a related place, family member, time, and day, including also the corresponding pronouns to the Gender of the person being discussed. We also create 13 non-informative sentences, and concatenate them before or after the template such that there is a correlation between each label and three of those sentences.16 This is performed so that we have other information that could be valuable for the classifier other than the person’s name and the emotion word. Also, to further prevent memorization, we include emotion words that are ambiguous and can describe multiple mood states. Our enriched data set consists of 33,738 sentences generated by 42 templates that are longer and much more diverse than the templates used in the original EEC. While still synthetic and somewhat unrealistic, our data set has much longer sentences, has more features that are predictive of the label, and is harder for the classifier to memorize.

* *Associated task:* classification (single-label classification)
	* classification of the sentences according to the 'gender', 'race' or 'POMS' (profile of mood states)
* *Domain:* Research / Education
* *Type:* Synthetic
* *Instance count:* 33738 sentences (according to paper)
* *Data types:* String, Numeric
* *Missing values:* ~ (race attributed randomly when missing in the 'gender treatement' splits)
* *Dataset infos and download:* [CausaLM repository](https://github.com/amirfeder/CausaLM) 

Introduced in:
Feder, A., Oved, N., Shalit, U., & Reichart, R. (2021). [Causalm: Causal model explanation through counterfactual language models.](https://direct.mit.edu/coli/article/47/2/333/98518) Computational Linguistics, 47(2), 333-386.

## Personal notes:

The splits provided by the authors of the "CausaLM" article contain pairs of 'factual' and 'counterfactual' examples. For the evaluation of a model's ability to predict 'gender', 'race' or mood state ('POMS'), this notion of pairs is unnecessary. So, for each split in the dataset we collected the unique instances they contain, an instance being either a factual example or a counterfactual example in the data provided. Below are the statistics for the distribution of these unique instances in the different splits and the 'overlaps' between the different splits (i.e. the rate of unique instances that appear in both splits of the complete dataset).

## Treatments

### Gender as a treatment: 
Total number of unique observations: 30,055 unique sentences
Number of unique observations per split and overlap with the other splits:
* train: 25,169 unique sentences (overlap w/ validation: 6,796, w/ test: 8,184)
* validation: 9,505 unique sentences (overlap w/ train: 6,796, w/ test: 3,157)
* test: 11,422 unique sentences (overlap w/ train: 8,184, w/ validation: 3,157)
* overlap between 'train + validation' and 'test': 9,245 (~81% of the train set)
For evaluation, I build a train/test/split that has no overlap between the different splits of the dataset with the following characteristics: 

| Total number of instances| #train    | #validation | #test | Comments                       |
| ------------------------ | --------- | ----------- | ----- | ------------------------------ |
| 30,005 | 25,169 | 2,709 | 2,177 | |
|  | *83.88%* | *9.03%* | *7.26%* | |

Random attribution of Race values:
Some sentences have no race value (for ex. 'I noticed my boyfriend in the church yesterday.'), a random race has been attributed to each of these sentences. 
Here are statistics about sentences with no race value per split:
train set: 7636 sentences (30.34% of the train set)
validation set: 811 sentences (29.94% of the validation set)
test set: 701 sentences (32.20% of the test set)
With 32.20% of the test set that have no race value, we can expect a test accuracy when predicting race that is around (100%-32.20%)%+0.5*32.20% ≈ 84% at most.

POMS distribution in sets (train, validation, test):
* anger: 22.38% - 23.07% - 21.68%
* fear: 23.25% - 23.48% - 25.17%
* joy: 23.42% - 24.10% - 23.89%
* sadness: 23.43% - 23.77% - 22.88%
* neutral: 7.51% - 5.57% - 6.38%

Race_label distribution in sets (train, validation, test):
* African-American: 49.97% - 52.05% - 51.17%
* European: 50.03% - 47.95% - 48.83%

Gender distribution in sets (train, validation, test):
* male: 49.97% - 49.72% - 50.53%
* female: 50.03% - 50.28% - 49.47%

### Race as a treatment:
Total number of unique observations: 20,952 unique sentences
Number of unique observations per split and overlap with the other splits:
* train: 17,552 unique sentences (overlap w/ validation: 4,792, w/ test: 5,672)
* validation: 6,667 unique sentences (overlap w/ train: 4,792, w/ test: 2,198)
* test: 7,931 unique sentences (overlap w/ train: 5,672, w/ validation: 2,198)
* overlap between 'train + validation' and 'test': 6,406 
For evaluation, I build a train/test/split that has no overlap between the different splits of the dataset with the following characteristics: 

| Total number of instances| #train    | #validation | #test | Comments                       |
| ------------------------ | --------- | ----------- | ----- | ------------------------------ |
| 20,952 | 17,552 | 1,875 | 1,525 | |
|  | *83.77%* | *8,95%* | *7.28%* | |

POMS distribution in sets (train, validation, test):
* anger: 22.37% - 22.24% - 22.95%
* fear: 23.02% - 22.88% - 23.48%
* joy: 23.89% - 25.12% - 23.41%
* sadness: 23.26% - 23.79% - 24.92%
* neutral: 7.45% - 5.97% - 5.25%


Race_label distribution in sets (train, validation, test):
* African-American: 49.76% - 48.64% - 49.77%
* European: 50.24% - 51.36% - 50.23%

Gender distribution in sets (train, validation, test):
* male: 49.78% - 51.79% - 48.98%
* female: 50.22% - 48.21% - 51.02%

#### Evaluation

Gender treatment
POMS

| Method               | max. # tokens    | Accuracy       | config. id       | Comments                       |
| -------------------- | ---------------- | -------------- | ---------------- | ------------------------------ |
| BSC                  | 128              |                |                  |                                |
| BWA                  | 64               |  94.35         |  EEEC-gender_64_BWA_POMS                |                                |